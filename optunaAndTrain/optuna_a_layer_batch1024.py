#!/usr/bin/env python
# coding: utf-8

# ## 1.å¯¼å…¥åŒ…
import torch
import torch.nn as nn
import torch.optim as optim
import re
import numpy as np
from sklearn.model_selection import train_test_split

np.set_printoptions(threshold=np.inf)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

## åœ¨æ¯æ¬¡è¿­ä»£å®Œæˆåè°ƒç”¨è¯¥å‡½æ•°æ¥é‡Šæ”¾æœªä½¿ç”¨çš„æ˜¾å­˜
torch.cuda.empty_cache()

"""
TRUE
function:ç”¨æ¥å¯¹aå€¼è¿›è¡Œè¶…å‚æ•°è°ƒä¼˜ã€‚
plan:è€ƒè™‘å¯¹aå€¼æ ‡ç­¾è¿›è¡Œæ•°æ®é¢„å¤„ç†ï¼Œåˆ é™¤é‚£äº›>1 & <0çš„å¼‚å¸¸å€¼ï¼Œå¯ä»¥è€ƒè™‘æ•°æ®æ ‡å‡†åŒ–æˆ–è€…åŠ å…¥sigmoid
"""


"""
å·²å®Œæˆç¬¬ï¼š 1 ä¸ªepoch! Train Loss: 8.532438956201077 Test Loss: 1.6267098747193813
å·²å®Œæˆç¬¬ï¼š 2 ä¸ªepoch! Train Loss: 6.524033911526203 Test Loss: 1.6227780878543854
å·²å®Œæˆç¬¬ï¼š 3 ä¸ªepoch! Train Loss: 6.491955656558275 Test Loss: 1.6219284012913704
æ¨¡å‹è®­ç»ƒå’Œæµ‹è¯•å…±ç”¨äº†: 235.96732807159424 ç§’ï¼
all of tasks Finished
[32m[I 2023-07-28 10:46:20,552][0m Trial 6 finished with value: 6.491955656558275 and parameters: {'batch_size': 1024, 'dropout': 0.20425596466776189, 'layers': 6, 'lr': 0.001497758981551898, 'optimizer': 'Adam'}. Best is trial 6 with value: 6.491955656558275.
"""
# ## 2.åŠ è½½æ•°æ®
# ç›´æ¥åŠ è½½npyæ–‡ä»¶ä¸ºnumpyæ ¼å¼
"""
æ³¨æ„è¿™é‡Œä½¿ç”¨äº†åˆ‡ç‰‡ï¼Œå¹¶ä¸”æ•°æ®æ‰€åœ¨ä½ç½®æ˜¯..ï¼Œä¸æ˜¯.
"""
all_data = np.load('../data/all_data.npy')
# #ç›´æ¥åŠ è½½npyæ–‡ä»¶ä¸ºnumpyæ ¼å¼,æ³¨æ„æ ‡ç­¾æ˜¯é¢å¿ƒå€¼ï¼Œä¸æ˜¯aå€¼
all_label = np.load('../data/all_label_repair01.npy')##############æ¢æˆæ–°çš„å¤„ç†å0-1çš„label

# all_data = np.load('../data/all_data.npy')[:20000]
# all_label = np.load('../data/all_label.npy')[:20000]

all_data = torch.tensor(all_data).float()
all_label = torch.tensor(all_label).float()


# ## 3.æ„å»ºæ¨¡å‹
#ç¥ç»ç½‘ç»œæ¨¡å‹
import torch
import torch.nn as nn

class Net(nn.Module):
    def __init__(self, num_output_channels, dropout, layers, hidden_units):
        super(Net, self).__init__()

        self.layers = nn.ModuleList()  # ç”¨äºå­˜å‚¨æ¯ä¸ªå±‚çš„åˆ—è¡¨

        # æ·»åŠ å·ç§¯å±‚ã€æ¿€æ´»å‡½æ•°ã€dropoutå±‚
        for i in range(layers):
            if i == 0:
                self.layers.append(nn.Conv2d(2, hidden_units, kernel_size=3, stride=1, padding=1))
            else:
                self.layers.append(nn.Conv2d(hidden_units, hidden_units, kernel_size=3, stride=1, padding=1))
            self.layers.append(nn.ReLU())
            self.layers.append(nn.Dropout(p=dropout))

        # æ·»åŠ æœ€åä¸€å±‚å·ç§¯å±‚
        self.conv_final = nn.Conv2d(hidden_units, num_output_channels, kernel_size=3, stride=1, padding=1)

    def forward(self, x):
        # è¿è¡Œæ¯ä¸ªå±‚çš„forwardæ–¹æ³•
        for layer in self.layers:
            x = layer(x)

        x = self.conv_final(x)

        return x


import optuna
import time
def objective1(trial):
    batch_size = trial.suggest_categorical('batch_size', [512,1024])
    dropout = trial.suggest_uniform('dropout', 0.1, 0.5)
    layers = trial.suggest_categorical('layers', [6,8,12])
    lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)
    optimizer_name = trial.suggest_categorical("optimizer", ["Adam"])


    num_output_channels = 4
    # ç”Ÿæˆæ•°æ®é›†
    x_train, x_test, y_train, y_test = train_test_split(all_data, all_label, test_size=0.2)

    # è®¾ç½®ç§å­æ•°
    seed = 42
    torch.manual_seed(seed)

    # åˆ’åˆ†æ•°æ®é›†
    trainset = torch.utils.data.TensorDataset(x_train, y_train)
    trainloader = torch.utils.data.DataLoader(
        trainset, batch_size=batch_size, shuffle=True)

    # åˆ’åˆ†æ•°æ®é›†
    testset = torch.utils.data.TensorDataset(x_test, y_test)
    testloader = torch.utils.data.DataLoader(
        testset, batch_size=batch_size, shuffle=True)

    # åˆ›å»ºæ¨¡å‹å®ä¾‹ï¼Œå¹¶å°†æ¨¡å‹ç§»åŠ¨åˆ°GPUè®¾å¤‡ä¸Šè¿›è¡Œè®¡ç®—
    net = Net(num_output_channels,dropout,layers,64).to(device)

    # åŠ é€Ÿè®­ç»ƒï¼šå¦‚æœæœ‰å¤šä¸ªGPUï¼Œåˆ™ä½¿ç”¨DataParallelæ¨¡å—
    if torch.cuda.device_count() > 1:
        net = nn.DataParallel(net)
        print("é‡‡ç”¨DataParallelåŠ é€Ÿï¼Œdevice_countä¸ªæ•°ä¸ºï¼š",str(torch.cuda.device_count()))

    # å®šä¹‰æŸå¤±å‡½æ•°ä¸ºå‡æ–¹è¯¯å·®
    criterion = nn.MSELoss()

    # è·å–è¦è°ƒä¼˜çš„è¶…å‚æ•°å€¼
    optimizer = getattr(optim, optimizer_name)(net.parameters(), lr=lr)
        

    # è®­ç»ƒæ¨¡å‹
    num_epochs = 6
    train_loss = []
    test_loss = []
    
    best_loss = float('inf')  # åˆå§‹åŒ–æœ€ä½³éªŒè¯é›†æŸå¤±å€¼ä¸ºæ­£æ— ç©·å¤§
    patience = 15  # è®¾ç½®è¿ç»­å¤šå°‘æ¬¡éªŒè¯é›†æŸå¤±å€¼ä¸ä¸‹é™æ—¶åœæ­¢è®­ç»ƒ
    count = 0  # è®°å½•è¿ç»­ä¸ä¸‹é™æ¬¡æ•°
    
    start_time =  time.time()
    for epoch in range(num_epochs):
        running_train_loss = 0.0
        net.train()#åŠ äº†è¿™ä¸ª,ä½¿ç”¨dropoutå’Œbatch-normalization
        for i, (inputs, labels) in enumerate(trainloader):
            inputs, labels = inputs.to(device), labels.to(device)

            optimizer.zero_grad()

            outputs = net(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_train_loss += loss.item()

        train_loss.append(running_train_loss)
        
        running_test_loss = 0.0
        net.eval()#åŠ äº†è¿™ä¸ª,ä¸ä½¿ç”¨dropoutå’Œbatch-normalizationã€ä½¿ç”¨æ‰€æœ‰ç½‘ç»œè¿æ¥ï¼Œä¸èˆå¼ƒç¥ç»å…ƒï¼Œä¸è¿›è¡Œåå‘ä¼ æ’­
        with torch.no_grad():#èŠ‚çœGPUå’Œæ˜¾å­˜
            for i, (inputs, labels) in enumerate(testloader):
                inputs, labels = inputs.to(device), labels.to(device)
                outputs = net(inputs)
                loss = criterion(outputs, labels)
                running_test_loss += loss.item()
        
            
            test_loss.append(running_test_loss)
            
            
        print("å·²å®Œæˆç¬¬ï¼š", str(epoch+1), "ä¸ªepoch! Train Loss:", running_train_loss, "Test Loss:", running_test_loss)

        # æ—©åœæ³•
        """
        å¦‚æœ<è¿ç»­å¤šä¸ª epoch> çš„<éªŒè¯é›†æŸå¤±å€¼>éƒ½æ²¡æœ‰<ä¸‹é™>ï¼Œå³éªŒè¯é›†æŸå¤±å€¼ä¸å†é™ä½ï¼Œé‚£ä¹ˆå°±ä¼šè®¤ä¸ºæ¨¡å‹å·²ç»è¿‡æ‹Ÿåˆæˆ–è€…æ— æ³•ç»§ç»­æ”¹å–„ã€‚
        è¿™æ—¶ï¼Œè®­ç»ƒä¼šæå‰åœæ­¢ï¼Œå¹¶ä¿å­˜å½“å‰çš„æ¨¡å‹å‚æ•°
        """
        if running_test_loss < best_loss:

            best_loss = running_test_loss
            count = 0 #è¿ç»­åæ¬¡æµ‹è¯•é›†çš„epoch lossä¸ä¸‹é™ï¼Œæ•…åªè¦åˆä¸€æ¬¡ä¸‹é™ï¼Œå°±æ¸…é›¶é‡æ–°è®¡ç®—
        else:
            count += 1
            if count >= patience:
                print(f"éªŒè¯é›†æŸå¤±å€¼è¿ç»­{patience}æ¬¡ä¸ä¸‹é™ï¼Œåœæ­¢è®­ç»ƒï¼")
                break

    
    end_time = time.time()
    process_time = end_time - start_time
    print(f"æ¨¡å‹è®­ç»ƒå’Œæµ‹è¯•å…±ç”¨äº†: {process_time} ç§’ï¼")
    print('all of tasks Finished')
    
    # ä¿å­˜æ•´ä¸ªæ¨¡å‹
#     torch.save(net, save_model_path)
    
    if trial.should_prune():
        raise optuna.exceptions.TrialPruned()

    # è¿”å›è®­ç»ƒé›†ä¸Šçš„æœ€ç»ˆæŸå¤±ä½œä¸ºç›®æ ‡å€¼
    return running_train_loss


"""
ä½¿ç”¨study.optimizeæ–¹æ³•æ¥è¿è¡ŒOptunaçš„è¶…å‚æ•°æœç´¢è¿‡ç¨‹ï¼Œè®¾ç½®n_trialså‚æ•°ä¸ºæœç´¢çš„è¿­ä»£æ¬¡æ•°ã€‚
æœç´¢ç»“æŸåï¼Œå¯ä»¥é€šè¿‡study.best_trialè·å–æœ€ä½³çš„è¶…å‚æ•°ç»„åˆï¼Œæ‰“å°å‡ºæœ€ä½³è¶…å‚æ•°ä»¥åŠæœ€å°åŒ–çš„æŸå¤±å‡½æ•°å€¼ã€‚
"""
study1 = optuna.create_study(direction='minimize')
study1.optimize(objective1, n_trials=50)

print("Best trial:")
trial = study1.best_trial
print("  Value: ", trial.value)
print("  Params: ")
for key, value in trial.params.items():
    print("    {}: {}".format(key, value))
    





